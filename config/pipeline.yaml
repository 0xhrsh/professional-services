# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

# Configuration for running the complete pipeline including modeling and evaluation.

# Absolute paths to non-code resources.
file_paths:
  queries: "/home/jupyter/github_msba_capstone/msba-capstone-2020/queries"

# Global config used by multiple pipeline steps. Also made available
# as parameters to all SQL queries.
global:
  # The        project_id contains datasets which are top-level containers to
  # organize and access tables. For more information, refer to the 
  # link: https://cloud.google.com/bigquery/docs/datasets-intro
  
  # The source project_id and dataset contain the complaints table which
  # is read and stored in the destination project_id for feature
  # extraction and training.
  # Source project and dataset configuration.
  source_project_id: "bigquery-public-data"
  source_dataset: "cfpb_complaints"
  source_table: "complaint_database"
  
  # Destination project and dataset configuration.
  # Enter the value of your project_id below.
  destination_project_id: ""
  destination_dataset: "cfpb_complaints"

  # Clean and minor refined versions of source data.
  # cleaned_features_table - This table contains the columns - issue,
  # subissue, product and subproduct after cleaning the categories
  # nulls_removed_table - This table contains the rows after removing
  # null values in the columns - complaint_narrative and
  # company_response_to_consumer
  # clean_table - This table contains the rows after cleaning and
  # removing nulls
  cleaned_features_table: "complaints_clean_categories"
  nulls_removed_table: "complaints_nulls_removed"
  clean_table: "complaints_clean"
  
  # Split the data into a training set and a prediction set. The
  # training set is passed to the AutoML Tables for training
  # the model. The prediction set is used for batch prediction
  # after the model os trained.


  train_predict_split: "TrainPredictSplit"
  features_train_table: "FeaturesTrain"
  features_predict_table: "FeaturesPredict"

  # Output tables for predictions and failed predictions from the batch
  # prediction job, ex. numeric column recieved a string.
  predictions_table: "Predictions"
  failed_predictions_table: "FailedPredictions"
  
  # Evaluation
  eval_table: "Evaluation"
  eval_metrics_table: "EvaluationMetrics"

  # AutoML Parameters. It is assumed that no other datasets or models have
  # been created with these names, or the pipeline will fail. They can be
  # deleted using the client, or the UI.
  dataset_display_name: "CFPBDataset"
  model_display_name: "CFPBModel"
  automl_compute_region: "us-central1"

  # Final model will be trained on test data, metrics are currently based
  # on the predict split instead. AutoML Requires at least one row of test data

# Files with templated queries, in file_paths.queries.
query_files:
  remove_nulls: "remove_nulls.sql"
  clean_categories: "clean_categories.sql"
  combine_tables: "combine_tables.sql"
  train_predict_split: "train_and_predict_split.sql"
  prediction_features: "prediction_features.sql"
  training_features: "training_features.sql"

# Parameters specific to individual SQL pipeline steps.
query_params:

  removing_nulls:
    column1: "consumer_complaint_narrative"
    column2: "company_response_to_consumer"
    
  category_cleanup:
    old_issue1: "Dealing with your lender or servicer"
    old_issue2: "Dealing with my lender or servicer"
    new_issue1: "Other"
    new_issue2: "Dealing with lender or servicer"
    old_subprod1: "Other (i.e. phone, health club, etc.)"
    old_subprod2: "Loan"
    new_subprod1: "Other"
    new_subprod2: "Other Loan"
    old_subissue1: "Debt is not yours"
    old_subissue2: "Debt is not mine"
    old_subissue3: "Account status"
    new_subissue1: "Other"
    new_subissue2: "Incorrect debt"
    new_subissue3: "Account status incorrect"
    
  train_predict_split:
    train_threshold: 0.8
    test_threshold: 0.2
      

# Training parameters for the model.
model:
  # See https://cloud.google.com/automl-tables/docs/train for more details
  # Training objective and maximum train time, early stopping is enabled.
  train_budget_hours: 1
  optimization_objective: "MINIMIZE_LOG_LOSS"
  
  # See https://cloud.google.com/automl-tables/docs/prepare for more details on
  # the target and split columns.
  # Target column to predict
  target_column: "company_response_to_consumer"
  # Split dataset into training, validation, and test.
  split_column: "splitting"

  # Columns in dataset to exclude from training, will still appear in prediction.
  # Target (model.target_column), Split (model.split_column), Weight (unused),
  # and Key column (defined below in columns) must be in the
  # exclude_columns list or create_model will raise an exception.
  exclude_columns:
    - "complaint_id"
    - "date_received"
    - "company_public_response"
    - "company_name"
    - "tags"
    - "company_response_to_consumer"
    - "consumer_consent_provided"
    - "date_sent_to_company"
    - "timely_response"
    - "consumer_disputed"
    - "splitting"

  # Define the data type, nullability, and forecasting type for every column.
  # Values for type_code: "CATEGORY", "STRING", "FLOAT64", "TIMESTAMP".
  columns:

    "product":
      type_code: "CATEGORY"
      nullable: TRUE

    "subproduct":
      type_code: "CATEGORY"
      nullable: TRUE

    "issue":
      type_code: "CATEGORY"
      nullable: TRUE

    "subissue":
      type_code: "CATEGORY"
      nullable: TRUE

    "consumer_complaint_narrative":
      type_code: "STRING"
      nullable: FALSE

    "state":
      type_code: "CATEGORY"
      nullable: TRUE

    "zip_code":
      type_code: "CATEGORY"
      nullable: TRUE

    "complaint_id":
      type_code: "FLOAT64"
      nullable: FALSE

    "company_public_response":
      type_code: "CATEGORY"
      nullable: TRUE

    "company_name":
      type_code: "CATEGORY"
      nullable: TRUE

    "tags":
      type_code: "CATEGORY"
      nullable: TRUE

    "consumer_consent_provided":
      type_code: "CATEGORY"
      nullable: TRUE

    "submitted_via":
      type_code: "CATEGORY"
      nullable: TRUE

    "company_response_to_consumer":
      type_code: "CATEGORY"
      nullable: FALSE

    "timely_response":
      type_code: "CATEGORY"
      nullable: TRUE

    "consumer_disputed":
      type_code: "CATEGORY"
      nullable: TRUE

    "splitting":
      type_code: "CATEGORY"
      nullable: FALSE
